{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39913a4b-aa74-4561-a545-919fbf1b198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1012\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.33%\n",
      "F1 Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_feature(file_name, mfcc=True, chroma=True, mel=True, spectral=True, tonnetz=True):\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    result = np.array([])\n",
    "\n",
    "    # Ensure n_fft is never larger than the signal\n",
    "    n_fft = min(512, len(X))  # Reduce to 512 if the file is too short\n",
    "\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=60).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    \n",
    "    if chroma:\n",
    "        stft = np.abs(librosa.stft(X, n_fft=n_fft))\n",
    "        chroma_feat = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, chroma_feat))\n",
    "    \n",
    "    if mel:\n",
    "        mel_feat = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate, n_fft=n_fft).T, axis=0)\n",
    "        result = np.hstack((result, mel_feat))\n",
    "    \n",
    "    if spectral:\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=X, sr=sample_rate, n_fft=n_fft).T, axis=0)\n",
    "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=X, sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, spectral_contrast, spectral_bandwidth))\n",
    "\n",
    "    if tonnetz:\n",
    "        tonnetz_feat = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T, axis=0)\n",
    "        result = np.hstack((result, tonnetz_feat))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Define emotion mapping for RAVDESS\n",
    "emotions = {\n",
    "    '01': 'Neutral', '02': 'Calm', '03': 'Happy', '04': 'Sad',\n",
    "    '05': 'Angry', '06': 'Fearful', '07': 'Disgust', '08': 'Surprised'\n",
    "}\n",
    "observed_emo = set(emotions.values())\n",
    "\n",
    "# Load dataset function\n",
    "def load_data(test_size=0.25):\n",
    "    x, y = [], []\n",
    "\n",
    "    # Load RAVDESS dataset\n",
    "    for file in glob.glob('E:/RAVDESS/RAVDESS/Actor_*/*.wav'):\n",
    "        file_name = os.path.basename(file)\n",
    "        emotion = emotions.get(file_name.split('-')[2], None)\n",
    "        if emotion in observed_emo:\n",
    "            feature = extract_feature(file)\n",
    "            x.append(feature)\n",
    "            y.append(emotion)\n",
    "\n",
    "    # Load TESS dataset\n",
    "    tess_base = 'E:/TESS/'\n",
    "    for folder in os.listdir(tess_base):\n",
    "        folder_path = os.path.join(tess_base, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            parts = folder.split('_')\n",
    "            if len(parts) > 1:  # Ensures there's an emotion label\n",
    "                emotion_label = parts[1].capitalize()\n",
    "                if emotion_label in observed_emo:\n",
    "                    for file in glob.glob(f'{folder_path}/*.wav'):\n",
    "                        feature = extract_feature(file)\n",
    "                        x.append(feature)\n",
    "                        y.append(emotion_label)\n",
    "    \n",
    "    # Convert to NumPy arrays and split\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return train_test_split(x, y, test_size=test_size, train_size=0.75, random_state=9)\n",
    "\n",
    "# Load data\n",
    "x_train, x_test, y_train, y_test = load_data(test_size=0.25)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Train MLP Classifier\n",
    "model = MLPClassifier(\n",
    "    alpha=0.001,  # Reduced regularization\n",
    "    batch_size=128,  # Smaller batch size\n",
    "    epsilon=1e-08,\n",
    "    hidden_layer_sizes=(512, 256, 128),  # Deeper network\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=800  # More iterations\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3722e-eb3c-476e-8a20-4d1296191c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31abf69-311e-4db4-af55-678f5327a3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
